name: Playwright Tests
on:
  workflow_dispatch:
    inputs:
      environment:
        type: choice
        description: 'Environment to run tests against'
        options:
          - ALPHA
          - BETA
          - QA
          - IST
          - VPRIOR
          - VNEXT
          - PROD
        required: true
        default: ALPHA
env:
  CI: true
  SYS_ADMIN_USERNAME: ${{ secrets.SYS_ADMIN_USERNAME }}
  SYS_ADMIN_PASSWORD: ${{ secrets.SYS_ADMIN_PASSWORD }}
  SYS_ADMIN_FIRST_NAME: ${{ secrets.SYS_ADMIN_FIRST_NAME }}
  SYS_ADMIN_LAST_NAME: ${{ secrets.SYS_ADMIN_LAST_NAME }}
  SYS_ADMIN_EMAIL: ${{ secrets.SYS_ADMIN_EMAIL }}
  TEST_ENV: ${{ github.event.inputs.environment }}
  ALPHA_INSTANCE_URL: ${{ secrets.ALPHA_INSTANCE_URL }}
  BETA_INSTANCE_URL: ${{ secrets.BETA_INSTANCE_URL }}
  QA_INSTANCE_URL: ${{ secrets.QA_INSTANCE_URL }}
  IST_INSTANCE_URL: ${{ secrets.IST_INSTANCE_URL }}
  VPRIOR_INSTANCE_URL: ${{ secrets.VPRIOR_INSTANCE_URL }}
  VNEXT_INSTANCE_URL: ${{ secrets.VNEXT_INSTANCE_URL }}
  PROD_INSTANCE_URL: ${{ secrets.PROD_INSTANCE_URL }}
jobs:
  generate_shards:
    name: 'Generate Shards'
    runs-on: ubuntu-latest
    outputs:
      shards: ${{ steps.generate_shards.outputs.shards }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Install jq
        run: |
          sudo apt-get update
          sudo apt-get install jq
      - name: Generate shards
        id: generate_shards
        run: |
          #!/bin/bash
          test_directory="tests"

          test_count=0

          while IFS= read -r file; do
            count=$(grep -c "test(" "$file")
            test_count=$((test_count + count))
          done < <(find "$test_directory" -type f -name '*.spec.ts')

          min_shards=10
          max_tests_per_shard=20

          num_of_shards=$((test_count / max_tests_per_shard))

          if [ "$num_of_shards" -le "$min_shards" ]; then
            num_of_shards=$min_shards
          fi

          shards_array=()

          for ((i=1; i<=$num_of_shards; i++)); do
            shards_array+=("$i/$num_of_shards")
          done

          json_shards_array=$(jq -n -c --arg arr "$(printf '%s\n' "${shards_array[@]}")" '$arr | split("\n")')

          # Output the result and the array
          echo "Total tests: $test_count"
          echo "Total shards: $num_of_shards"
          echo "shards=${shards_array[@]}"
          echo "shards=$json_shards_array" >> $GITHUB_OUTPUT
  run_tests:
    name: 'Playwright Tests - ${{ github.event.inputs.environment }} - ${{ matrix.project }} - Shard ${{ matrix.shard }}'
    needs: generate_shards
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/playwright:v1.39.0-jammy
    strategy:
      fail-fast: false
      matrix:
        project: [chrome, edge]
        shard: ${{ fromJson(needs.generate_shards.outputs.shards) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: latest
      - name: Install dependencies
        run: npm ci
      - name: Run your tests
        run: npx playwright test --project=${{ matrix.project }} --shard=${{ matrix.shard }}
      - name: Rename blob-reports
        if: always()
        run: for file in blob-report/*; do [ -f "$file" ] && mv "$file" "blob-report/${{ matrix.project }}-$(basename "$file")"; done
      - name: Upload blob report'
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: all-blob-reports
          path: blob-report
          retention-days: 1
  merge_reports_and_publish:
    name: 'Merge Reports and Publish'
    if: always()
    needs: [run_tests]
    env:
      VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
      VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: latest
      - name: Install dependencies
        run: npm ci
      - name: Download blob reports
        uses: actions/download-artifact@v3
        with:
          name: all-blob-reports
          path: all-blob-reports
      - name: Rename reports
        run: count=1; for file in $(find ./all-blob-reports -maxdepth 1 -type f -name "*.zip"); do mv "$file" "all-blob-reports/report-$count.zip"; count=$((count+1)); done
      - name: Merge into HTML Report
        run: npx playwright merge-reports --reporter html ./all-blob-reports
      - name: Upload HTML report
        uses: actions/upload-artifact@v3
        with:
          name: html-report-attempt-${{ github.run_attempt }}
          path: playwright-report
          retention-days: 14
      - name: Get date and time
        id: date
        run: echo "value=$(($(date '+%s%N' | cut -b1-13) / 1))" >> $GITHUB_OUTPUT
      - name: Rename reports
        run: mv playwright-report ${{ steps.date.outputs.value }}-${{ env.TEST_ENV }}-${{ needs.run_tests.result }}
      - name: Commit report to report site
        uses: cpina/github-action-push-to-another-repository@v1.7.2
        env:
          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
        with:
          source-directory: ${{ steps.date.outputs.value }}-${{ env.TEST_ENV }}-${{ needs.run_tests.result }}
          destination-github-username: 'StevanFreeborn'
          user-email: '65925598+StevanFreeborn@users.noreply.github.com'
          destination-repository-name: 'onspring-qa-playwright-reports'
          target-branch: 'main'
          commit-message: 'Add new report'
          target-directory: 'reports/${{ steps.date.outputs.value }}-${{ env.TEST_ENV }}-${{ needs.run_tests.result }}/'
      - name: Install vercel cli
        run: npm i -g vercel@latest
      # only deploy to preview if tests fail
      - name: Pull vercel preview environment information
        run: vercel pull --yes --environment=production --token=${{ secrets.VERCEL_TOKEN }}
        if: ${{ needs.run_tests.result == 'failure' }}
      - name: Deploy to vercel as preview # this could fail if file size is > 100 MB. This is acceptable for now.
        run: vercel --yes --token ${{ secrets.VERCEL_TOKEN }}
        if: ${{ needs.run_tests.result == 'failure' }}

      # only deploy to production if all tests pass
      - name: Pull vercel production environment information
        run: vercel pull --yes --environment=production --token=${{ secrets.VERCEL_TOKEN }}
        if: ${{ needs.run_tests.result == 'success' }}
      - name: Deploy to vercel as production # this could fail if file size is > 100 MB. This is acceptable for now.
        run: vercel --yes --prod --token ${{ secrets.VERCEL_TOKEN }}
        if: ${{ needs.run_tests.result == 'success' }}
